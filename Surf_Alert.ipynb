{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surf Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import smtplib\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neah Bay Buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NDBC - Station 46087 Recent Data\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.ndbc.noaa.gov/station_page.php?station=46087\"  # Replace with the URL of the website you want to scrape\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract specific information from the HTML\n",
    "title = soup.title.text  # Extract the page title\n",
    "tables = soup.find_all(\"table\")\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Title:\", title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = tables[5].find_all(\"tr\")\n",
    "del rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_rows = rows\n",
    "\n",
    "html_table = f'<table>{html_rows}</table>'\n",
    "\n",
    "soup = BeautifulSoup(html_table, 'html.parser')\n",
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in table.find_all('tr'):\n",
    "    date_tag = row.find('span', class_='nowrap')\n",
    "    date = date_tag.get_text(strip=True)\n",
    "    time = date_tag.find_next_sibling('span').get_text(strip=True)\n",
    "    values = [td.get_text(strip=True) for td in row.find_all('td')]\n",
    "    data.append({'Date': date, 'Time': time, 'Values': values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "date_format = \"%Y-%m-%d\"\n",
    "time = []\n",
    "time_format = \"%I:%M %p\"\n",
    "wave_height = []\n",
    "period = []\n",
    "direction = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    date.append(datetime.strptime(data[i]['Date'],date_format))\n",
    "    time.append(datetime.strptime(data[i]['Time'],time_format).time())\n",
    "    wave_height.append(float(data[i]['Values'][0]))\n",
    "    period.append(float(data[i]['Values'][2]))\n",
    "    direction.append(data[i]['Values'][3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'Date':date,\n",
    "                    'Time':time,\n",
    "                    'Wave Height [ft]':wave_height,\n",
    "                    'Period [s]':period,\n",
    "                    'Swell Direction':direction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = tables[3].find_all(\"tr\")\n",
    "del rows[0]\n",
    "\n",
    "html_rows = rows\n",
    "\n",
    "html_table = f'<table>{html_rows}</table>'\n",
    "\n",
    "soup = BeautifulSoup(html_table, 'html.parser')\n",
    "table = soup.find('table')\n",
    "\n",
    "data = []\n",
    "for row in table.find_all('tr'):\n",
    "    date_tag = row.find('span', class_='nowrap')\n",
    "    date = date_tag.get_text(strip=True)\n",
    "    time = date_tag.find_next_sibling('span').get_text(strip=True)\n",
    "    values = [td.get_text(strip=True) for td in row.find_all('td')]\n",
    "    data.append({'Date': date, 'Time': time, 'Values': values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "date_format = \"%Y-%m-%d\"\n",
    "time = []\n",
    "time_format = \"%I:%M %p\"\n",
    "wind_direction = []\n",
    "wind_speed = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data[i]['Values'][1] == '-':\n",
    "        continue \n",
    "    date.append(datetime.strptime(data[i]['Date'],date_format))\n",
    "    time.append(datetime.strptime(data[i]['Time'],time_format).time())\n",
    "    wind_direction.append(data[i]['Values'][0])\n",
    "    wind_speed.append((float(data[i]['Values'][1])*1.852))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'Date':date,\n",
    "                    'Time':time,\n",
    "                    'Wind Direction':wind_direction,\n",
    "                    'Wind Speed [kts]':wind_speed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to string format in case it's already datetime\n",
    "df3[\"Date\"] = df3[\"Date\"].astype(str)\n",
    "df2[\"Date\"] = df2[\"Date\"].astype(str)\n",
    "\n",
    "# Convert Time to string format if it's not already\n",
    "df3[\"Time\"] = df3[\"Time\"].astype(str)\n",
    "df2[\"Time\"] = df2[\"Time\"].astype(str)\n",
    "\n",
    "\n",
    "# Convert Date and Time columns to a single Datetime column in both dataframes\n",
    "df3[\"Datetime\"] = pd.to_datetime(df3[\"Date\"] + \" \" + df3[\"Time\"])\n",
    "df2[\"Datetime\"] = pd.to_datetime(df2[\"Date\"] + \" \" + df2[\"Time\"])\n",
    "\n",
    "# Merge dataframes on the Datetime column, keeping only matching rows\n",
    "merged_df = pd.merge(df3, df2, on=\"Datetime\", how=\"inner\")\n",
    "\n",
    "# Move the Datetime column to the first position and remove redundant Date and Time columns\n",
    "columns_to_keep = [\"Datetime\", \"Wave Height [ft]\", \"Swell Direction\", \"Period [s]\", \"Wind Direction\", \"Wind Speed [kts]\"]\n",
    "merged_df = merged_df[columns_to_keep].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = buoy.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime            2025-05-23 14:10:00\n",
      "Wave Height [ft]                    2.6\n",
      "Swell Direction                     WSW\n",
      "Period [s]                          8.3\n",
      "Wind Direction                      WSW\n",
      "Wind Speed [kts]                   14.4\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Message sent! ID: 196ff3e81f55f75b\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import base64\n",
    "from email.message import EmailMessage\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# If modifying scopes, delete the token.json file\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "\n",
    "def gmail_send_message():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "\n",
    "    # If there are no valid credentials, do OAuth flow\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for next time\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    # Create the message\n",
    "    message = EmailMessage()\n",
    "    message.set_content(\"This is an automated surf alert!\"+str(now))\n",
    "    message['To'] = 'neahbuoy@gmail.com'\n",
    "    message['From'] = 'neahbuoy@gmail.com'\n",
    "    message['Subject'] = 'Surf’s up!'\n",
    "\n",
    "    encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "    create_message = {'raw': encoded_message}\n",
    "\n",
    "    send_message = service.users().messages().send(userId='me', body=create_message).execute()\n",
    "    print(f\"✅ Message sent! ID: {send_message['id']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if now[1] > 3 and now[3] >= 8:\n",
    "        gmail_send_message()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
